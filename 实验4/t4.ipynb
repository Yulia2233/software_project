{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1jV3uZC-Ub3",
        "outputId": "00980fbc-92cb-4fb9-bd23-f8b6ee77f589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-10-17 10:22:45--  http://www.ehu.eus/ccwintco/uploads/6/67/Indian_pines_corrected.mat\n",
            "Resolving www.ehu.eus (www.ehu.eus)... 158.227.0.65, 2001:720:1410::65\n",
            "Connecting to www.ehu.eus (www.ehu.eus)|158.227.0.65|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.ehu.eus/ccwintco/uploads/6/67/Indian_pines_corrected.mat [following]\n",
            "--2024-10-17 10:22:45--  https://www.ehu.eus/ccwintco/uploads/6/67/Indian_pines_corrected.mat\n",
            "Connecting to www.ehu.eus (www.ehu.eus)|158.227.0.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5953527 (5.7M)\n",
            "Saving to: ‘Indian_pines_corrected.mat’\n",
            "\n",
            "Indian_pines_correc 100%[===================>]   5.68M   235KB/s    in 26s     \n",
            "\n",
            "2024-10-17 10:23:12 (222 KB/s) - ‘Indian_pines_corrected.mat’ saved [5953527/5953527]\n",
            "\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2024-10-17 10:23:12--  https://www.ehu.eus/ccwintco/uploads/c/c4/Indian_pines_gt.mat\n",
            "Resolving www.ehu.eus (www.ehu.eus)... 158.227.0.65, 2001:720:1410::65\n",
            "Connecting to www.ehu.eus (www.ehu.eus)|158.227.0.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1125 (1.1K)\n",
            "Saving to: ‘Indian_pines_gt.mat’\n",
            "\n",
            "Indian_pines_gt.mat 100%[===================>]   1.10K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-10-17 10:23:12 (37.5 MB/s) - ‘Indian_pines_gt.mat’ saved [1125/1125]\n",
            "\n",
            "Collecting spectral\n",
            "  Downloading spectral-0.23.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from spectral) (1.26.4)\n",
            "Downloading spectral-0.23.1-py3-none-any.whl (212 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.9/212.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: spectral\n",
            "Successfully installed spectral-0.23.1\n"
          ]
        }
      ],
      "source": [
        "! wget http://www.ehu.eus/ccwintco/uploads/6/67/Indian_pines_corrected.mat\n",
        "! wget http://www.ehu.eus/ccwintco/uploads/c/c4/Indian_pines_gt.mat\n",
        "! pip install spectral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5L1kMe4m-8kP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "import spectral\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eR0VSaC-8m0"
      },
      "outputs": [],
      "source": [
        "class_num = 16\n",
        "windowSize = 25\n",
        "K = 30\n",
        "rate = 16\n",
        "\n",
        "class HybridSN(nn.Module):\n",
        "  #定义各个层的部分\n",
        "  def __init__(self):\n",
        "    super(HybridSN, self).__init__()\n",
        "    self.S = windowSize\n",
        "    self.L = K;\n",
        "\n",
        "    self.conv1 = nn.Conv3d(in_channels=1, out_channels=8, kernel_size=(7, 3, 3))\n",
        "    self.conv2 = nn.Conv3d(in_channels=8, out_channels=16, kernel_size=(5, 3, 3))\n",
        "    self.conv3 = nn.Conv3d(in_channels=16, out_channels=32, kernel_size=(3, 3, 3))\n",
        "\n",
        "    #不懂 inputX经过三重3d卷积的大小\n",
        "    inputX = self.get2Dinput()\n",
        "    inputConv4 = inputX.shape[1] * inputX.shape[2]\n",
        "    # conv4 （24*24=576, 19, 19），64个 3x3 的卷积核 ==>（（64, 17, 17）\n",
        "    self.conv4 = nn.Conv2d(inputConv4, 64, kernel_size=(3, 3))\n",
        "\n",
        "    #self-attention\n",
        "    self.sa1 = nn.Conv2d(64, 64//rate, kernel_size=1)\n",
        "    self.sa2 = nn.Conv2d(64//rate, 64, kernel_size=1)\n",
        "\n",
        "    # 全连接层（256个节点） # 64 * 17 * 17 = 18496\n",
        "    self.dense1 = nn.Linear(18496, 256)\n",
        "    # 全连接层（128个节点）\n",
        "    self.dense2 = nn.Linear(256, 128)\n",
        "    # 最终输出层(16个节点)\n",
        "    self.dense3 = nn.Linear(128, class_num)\n",
        "\n",
        "    #让某个神经元的激活值以一定的概率p，让其停止工作，这次训练过程中不更新权值，也不参加神经网络的计算。\n",
        "    #self.drop = nn.Dropout(p = 0.4)\n",
        "    #改成0.43试试\n",
        "    self.drop = nn.Dropout(p = 0.43)\n",
        "    self.soft = nn.Softmax(dim=1)\n",
        "    pass\n",
        "\n",
        "  #辅助函数，没怎么懂，求经历过三重卷积后二维的一个大小\n",
        "  def get2Dinput(self):\n",
        "    #torch.no_grad(): 做运算，但不计入梯度记录\n",
        "    with torch.no_grad():\n",
        "      x = torch.zeros((1, 1, self.L, self.S, self.S))\n",
        "      x = self.conv1(x)\n",
        "      x = self.conv2(x)\n",
        "      x = self.conv3(x)\n",
        "    return x\n",
        "    pass\n",
        "\n",
        "  #必须重载的部分，X代表输入\n",
        "  def forward(self, x):\n",
        "    #F在上文有定义torch.nn.functional，是已定义好的一组名称\n",
        "    out = F.relu(self.conv1(x))\n",
        "    out = F.relu(self.conv2(out))\n",
        "    out = F.relu(self.conv3(out))\n",
        "\n",
        "    # 进行二维卷积，因此把前面的 32*18 reshape 一下，得到 （576, 19, 19）\n",
        "    out = out.view(-1, out.shape[1] * out.shape[2], out.shape[3], out.shape[4])\n",
        "    out = F.relu(self.conv4(out))\n",
        "\n",
        "    # Squeeze 第三维卷成1了\n",
        "    weight = F.avg_pool2d(out, out.size(2))    #参数为输入，kernel\n",
        "\n",
        "    # Excitation: sa（压缩到16分之一）--Relu--fc（激到之前维度）--Sigmoid（保证输出为0至1之间）\n",
        "    weight = F.relu(self.sa1(weight))\n",
        "    weight = F.sigmoid(self.sa2(weight))\n",
        "    out = out * weight\n",
        "\n",
        "    # flatten: 变为 18496 维的向量，\n",
        "    out = out.view(out.size(0), -1)\n",
        "\n",
        "    out = F.relu(self.dense1(out))\n",
        "    out = self.drop(out)\n",
        "    out = F.relu(self.dense2(out))\n",
        "    out = self.drop(out)\n",
        "    out = self.dense3(out)\n",
        "    return out\n",
        "    pass\n",
        "# 随机输入，测试网络结构是否通\n",
        "# x = torch.randn(1, 1, 30, 25, 25)\n",
        "# net = HybridSN()\n",
        "# y = net(x)\n",
        "# print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqyjhDug-8pC"
      },
      "outputs": [],
      "source": [
        "# 对高光谱数据 X 应用 PCA 变换\n",
        "def applyPCA(X, numComponents):\n",
        "    newX = np.reshape(X, (-1, X.shape[2]))\n",
        "    pca = PCA(n_components=numComponents, whiten=True)\n",
        "    newX = pca.fit_transform(newX)\n",
        "    newX = np.reshape(newX, (X.shape[0], X.shape[1], numComponents))\n",
        "    return newX\n",
        "\n",
        "# 对单个像素周围提取 patch 时，边缘像素就无法取了，因此，给这部分像素进行 padding 操作\n",
        "def padWithZeros(X, margin=2):\n",
        "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
        "    x_offset = margin\n",
        "    y_offset = margin\n",
        "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
        "    return newX\n",
        "\n",
        "# 在每个像素周围提取 patch ，然后创建成符合 keras 处理的格式\n",
        "def createImageCubes(X, y, windowSize=5, removeZeroLabels = True):\n",
        "    # 给 X 做 padding\n",
        "    margin = int((windowSize - 1) / 2)\n",
        "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
        "    # split patches\n",
        "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
        "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
        "    patchIndex = 0\n",
        "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
        "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
        "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]\n",
        "            patchesData[patchIndex, :, :, :] = patch\n",
        "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
        "            patchIndex = patchIndex + 1\n",
        "    if removeZeroLabels:\n",
        "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
        "        patchesLabels = patchesLabels[patchesLabels>0]\n",
        "        patchesLabels -= 1\n",
        "    return patchesData, patchesLabels\n",
        "\n",
        "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState, stratify=y)\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ4mgyD0-8rF",
        "outputId": "0f3215e4-9de2-4ec2-cc6d-9917ef608055"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperspectral data shape:  (145, 145, 200)\n",
            "Label shape:  (145, 145)\n",
            "\n",
            "... ... PCA tranformation ... ...\n",
            "Data shape after PCA:  (145, 145, 30)\n",
            "\n",
            "... ... create data cubes ... ...\n",
            "Data cube X shape:  (10249, 25, 25, 30)\n",
            "Data cube y shape:  (10249,)\n",
            "\n",
            "... ... create train & test data ... ...\n",
            "Xtrain shape:  (1024, 25, 25, 30)\n",
            "Xtest  shape:  (9225, 25, 25, 30)\n",
            "before transpose: Xtrain shape:  (1024, 25, 25, 30, 1)\n",
            "before transpose: Xtest  shape:  (9225, 25, 25, 30, 1)\n",
            "after transpose: Xtrain shape:  (1024, 1, 30, 25, 25)\n",
            "after transpose: Xtest  shape:  (9225, 1, 30, 25, 25)\n"
          ]
        }
      ],
      "source": [
        "# 地物类别\n",
        "class_num = 16\n",
        "X = sio.loadmat('Indian_pines_corrected.mat')['indian_pines_corrected']\n",
        "y = sio.loadmat('Indian_pines_gt.mat')['indian_pines_gt']\n",
        "\n",
        "# 用于测试样本的比例\n",
        "test_ratio = 0.90\n",
        "# 每个像素周围提取 patch 的尺寸\n",
        "patch_size = 25\n",
        "# 使用 PCA 降维，得到主成分的数量\n",
        "pca_components = 30\n",
        "\n",
        "print('Hyperspectral data shape: ', X.shape)\n",
        "print('Label shape: ', y.shape)\n",
        "\n",
        "print('\\n... ... PCA tranformation ... ...')\n",
        "X_pca = applyPCA(X, numComponents=pca_components)\n",
        "print('Data shape after PCA: ', X_pca.shape)\n",
        "\n",
        "print('\\n... ... create data cubes ... ...')\n",
        "X_pca, y = createImageCubes(X_pca, y, windowSize=patch_size)\n",
        "print('Data cube X shape: ', X_pca.shape)\n",
        "print('Data cube y shape: ', y.shape)\n",
        "\n",
        "print('\\n... ... create train & test data ... ...')\n",
        "Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X_pca, y, test_ratio)\n",
        "print('Xtrain shape: ', Xtrain.shape)\n",
        "print('Xtest  shape: ', Xtest.shape)\n",
        "\n",
        "# 改变 Xtrain, Ytrain 的形状，以符合 keras 的要求\n",
        "Xtrain = Xtrain.reshape(-1, patch_size, patch_size, pca_components, 1)\n",
        "Xtest  = Xtest.reshape(-1, patch_size, patch_size, pca_components, 1)\n",
        "print('before transpose: Xtrain shape: ', Xtrain.shape)\n",
        "print('before transpose: Xtest  shape: ', Xtest.shape)\n",
        "\n",
        "# 为了适应 pytorch 结构，数据要做 transpose\n",
        "Xtrain = Xtrain.transpose(0, 4, 3, 1, 2)\n",
        "Xtest  = Xtest.transpose(0, 4, 3, 1, 2)\n",
        "print('after transpose: Xtrain shape: ', Xtrain.shape)\n",
        "print('after transpose: Xtest  shape: ', Xtest.shape)\n",
        "\n",
        "\n",
        "\"\"\" Training dataset\"\"\"\n",
        "class TrainDS(torch.utils.data.Dataset):\n",
        "    def __init__(self):\n",
        "        self.len = Xtrain.shape[0]\n",
        "        self.x_data = torch.FloatTensor(Xtrain)\n",
        "        self.y_data = torch.LongTensor(ytrain)\n",
        "    def __getitem__(self, index):\n",
        "        # 根据索引返回数据和对应的标签\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "    def __len__(self):\n",
        "        # 返回文件数据的数目\n",
        "        return self.len\n",
        "\n",
        "\"\"\" Testing dataset\"\"\"\n",
        "class TestDS(torch.utils.data.Dataset):\n",
        "    def __init__(self):\n",
        "        self.len = Xtest.shape[0]\n",
        "        self.x_data = torch.FloatTensor(Xtest)\n",
        "        self.y_data = torch.LongTensor(ytest)\n",
        "    def __getitem__(self, index):\n",
        "        # 根据索引返回数据和对应的标签\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "    def __len__(self):\n",
        "        # 返回文件数据的数目\n",
        "        return self.len\n",
        "\n",
        "# 创建 trainloader 和 testloader\n",
        "trainset = TrainDS()\n",
        "testset  = TestDS()\n",
        "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_loader  = torch.utils.data.DataLoader(dataset=testset,  batch_size=128, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ieli-FMs_GEf",
        "outputId": "10116aef-d216-4ee9-b5bc-ebbaba2bc550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch: 1]   [loss avg: 21.4413]   [current loss: 2.5262]\n",
            "[Epoch: 2]   [loss avg: 20.8035]   [current loss: 2.4512]\n",
            "[Epoch: 3]   [loss avg: 20.2353]   [current loss: 2.3367]\n",
            "[Epoch: 4]   [loss avg: 19.7401]   [current loss: 2.3196]\n",
            "[Epoch: 5]   [loss avg: 19.2546]   [current loss: 2.1407]\n",
            "[Epoch: 6]   [loss avg: 18.7880]   [current loss: 2.0813]\n",
            "[Epoch: 7]   [loss avg: 18.2291]   [current loss: 1.7246]\n",
            "[Epoch: 8]   [loss avg: 17.6550]   [current loss: 1.6794]\n",
            "[Epoch: 9]   [loss avg: 16.9731]   [current loss: 1.1375]\n",
            "[Epoch: 10]   [loss avg: 16.2229]   [current loss: 1.1901]\n",
            "[Epoch: 11]   [loss avg: 15.4479]   [current loss: 0.9045]\n",
            "[Epoch: 12]   [loss avg: 14.6670]   [current loss: 0.5879]\n",
            "[Epoch: 13]   [loss avg: 13.9164]   [current loss: 0.4792]\n",
            "[Epoch: 14]   [loss avg: 13.2068]   [current loss: 0.4678]\n",
            "[Epoch: 15]   [loss avg: 12.5469]   [current loss: 0.4557]\n",
            "[Epoch: 16]   [loss avg: 11.9289]   [current loss: 0.2027]\n",
            "[Epoch: 17]   [loss avg: 11.3410]   [current loss: 0.2488]\n",
            "[Epoch: 18]   [loss avg: 10.8380]   [current loss: 0.1806]\n",
            "[Epoch: 19]   [loss avg: 10.3673]   [current loss: 0.1988]\n",
            "[Epoch: 20]   [loss avg: 9.9329]   [current loss: 0.1785]\n",
            "[Epoch: 21]   [loss avg: 9.5068]   [current loss: 0.1348]\n",
            "[Epoch: 22]   [loss avg: 9.1166]   [current loss: 0.1696]\n",
            "[Epoch: 23]   [loss avg: 8.7543]   [current loss: 0.0613]\n",
            "[Epoch: 24]   [loss avg: 8.4181]   [current loss: 0.0826]\n",
            "[Epoch: 25]   [loss avg: 8.1142]   [current loss: 0.1261]\n",
            "[Epoch: 26]   [loss avg: 7.8321]   [current loss: 0.0524]\n",
            "[Epoch: 27]   [loss avg: 7.5606]   [current loss: 0.0667]\n",
            "[Epoch: 28]   [loss avg: 7.3030]   [current loss: 0.0228]\n",
            "[Epoch: 29]   [loss avg: 7.0623]   [current loss: 0.0068]\n",
            "[Epoch: 30]   [loss avg: 6.8467]   [current loss: 0.0397]\n",
            "[Epoch: 31]   [loss avg: 6.6399]   [current loss: 0.0379]\n",
            "[Epoch: 32]   [loss avg: 6.4475]   [current loss: 0.0854]\n",
            "[Epoch: 33]   [loss avg: 6.2616]   [current loss: 0.0276]\n",
            "[Epoch: 34]   [loss avg: 6.0869]   [current loss: 0.0308]\n",
            "[Epoch: 35]   [loss avg: 5.9205]   [current loss: 0.0384]\n",
            "[Epoch: 36]   [loss avg: 5.7667]   [current loss: 0.0190]\n",
            "[Epoch: 37]   [loss avg: 5.6184]   [current loss: 0.0263]\n",
            "[Epoch: 38]   [loss avg: 5.4846]   [current loss: 0.0586]\n",
            "[Epoch: 39]   [loss avg: 5.3497]   [current loss: 0.0189]\n",
            "[Epoch: 40]   [loss avg: 5.2254]   [current loss: 0.0585]\n",
            "[Epoch: 41]   [loss avg: 5.1028]   [current loss: 0.0583]\n",
            "[Epoch: 42]   [loss avg: 4.9891]   [current loss: 0.0586]\n",
            "[Epoch: 43]   [loss avg: 4.8819]   [current loss: 0.0531]\n",
            "[Epoch: 44]   [loss avg: 4.7759]   [current loss: 0.0069]\n",
            "[Epoch: 45]   [loss avg: 4.6736]   [current loss: 0.0091]\n",
            "[Epoch: 46]   [loss avg: 4.5765]   [current loss: 0.0215]\n",
            "[Epoch: 47]   [loss avg: 4.4860]   [current loss: 0.0498]\n",
            "[Epoch: 48]   [loss avg: 4.3978]   [current loss: 0.1287]\n",
            "[Epoch: 49]   [loss avg: 4.3145]   [current loss: 0.0314]\n",
            "[Epoch: 50]   [loss avg: 4.2310]   [current loss: 0.0140]\n",
            "[Epoch: 51]   [loss avg: 4.1576]   [current loss: 0.0801]\n",
            "[Epoch: 52]   [loss avg: 4.0861]   [current loss: 0.0795]\n",
            "[Epoch: 53]   [loss avg: 4.0140]   [current loss: 0.0350]\n",
            "[Epoch: 54]   [loss avg: 3.9471]   [current loss: 0.0419]\n",
            "[Epoch: 55]   [loss avg: 3.8822]   [current loss: 0.0594]\n",
            "[Epoch: 56]   [loss avg: 3.8165]   [current loss: 0.0045]\n",
            "[Epoch: 57]   [loss avg: 3.7545]   [current loss: 0.0391]\n",
            "[Epoch: 58]   [loss avg: 3.6930]   [current loss: 0.0117]\n",
            "[Epoch: 59]   [loss avg: 3.6327]   [current loss: 0.0057]\n",
            "[Epoch: 60]   [loss avg: 3.5795]   [current loss: 0.1370]\n",
            "[Epoch: 61]   [loss avg: 3.5259]   [current loss: 0.0126]\n",
            "[Epoch: 62]   [loss avg: 3.4727]   [current loss: 0.0238]\n",
            "[Epoch: 63]   [loss avg: 3.4204]   [current loss: 0.0009]\n",
            "[Epoch: 64]   [loss avg: 3.3698]   [current loss: 0.0302]\n",
            "[Epoch: 65]   [loss avg: 3.3211]   [current loss: 0.0070]\n",
            "[Epoch: 66]   [loss avg: 3.2744]   [current loss: 0.0051]\n",
            "[Epoch: 67]   [loss avg: 3.2275]   [current loss: 0.0136]\n",
            "[Epoch: 68]   [loss avg: 3.1835]   [current loss: 0.0063]\n",
            "[Epoch: 69]   [loss avg: 3.1394]   [current loss: 0.0161]\n",
            "[Epoch: 70]   [loss avg: 3.0991]   [current loss: 0.0058]\n",
            "[Epoch: 71]   [loss avg: 3.0581]   [current loss: 0.0543]\n",
            "[Epoch: 72]   [loss avg: 3.0168]   [current loss: 0.0102]\n",
            "[Epoch: 73]   [loss avg: 2.9773]   [current loss: 0.0345]\n",
            "[Epoch: 74]   [loss avg: 2.9392]   [current loss: 0.0114]\n",
            "[Epoch: 75]   [loss avg: 2.9024]   [current loss: 0.0066]\n",
            "[Epoch: 76]   [loss avg: 2.8652]   [current loss: 0.0067]\n",
            "[Epoch: 77]   [loss avg: 2.8306]   [current loss: 0.0432]\n",
            "[Epoch: 78]   [loss avg: 2.7966]   [current loss: 0.0354]\n",
            "[Epoch: 79]   [loss avg: 2.7634]   [current loss: 0.0039]\n",
            "[Epoch: 80]   [loss avg: 2.7316]   [current loss: 0.0139]\n",
            "[Epoch: 81]   [loss avg: 2.7004]   [current loss: 0.0219]\n",
            "[Epoch: 82]   [loss avg: 2.6688]   [current loss: 0.0154]\n",
            "[Epoch: 83]   [loss avg: 2.6395]   [current loss: 0.0091]\n",
            "[Epoch: 84]   [loss avg: 2.6096]   [current loss: 0.0080]\n",
            "[Epoch: 85]   [loss avg: 2.5806]   [current loss: 0.0298]\n",
            "[Epoch: 86]   [loss avg: 2.5526]   [current loss: 0.0117]\n",
            "[Epoch: 87]   [loss avg: 2.5273]   [current loss: 0.0058]\n",
            "[Epoch: 88]   [loss avg: 2.5023]   [current loss: 0.0401]\n",
            "[Epoch: 89]   [loss avg: 2.4758]   [current loss: 0.0201]\n",
            "[Epoch: 90]   [loss avg: 2.4511]   [current loss: 0.0496]\n",
            "[Epoch: 91]   [loss avg: 2.4260]   [current loss: 0.0088]\n",
            "[Epoch: 92]   [loss avg: 2.4011]   [current loss: 0.0605]\n",
            "[Epoch: 93]   [loss avg: 2.3768]   [current loss: 0.0496]\n",
            "[Epoch: 94]   [loss avg: 2.3530]   [current loss: 0.0009]\n",
            "[Epoch: 95]   [loss avg: 2.3293]   [current loss: 0.0057]\n",
            "[Epoch: 96]   [loss avg: 2.3056]   [current loss: 0.0047]\n",
            "[Epoch: 97]   [loss avg: 2.2832]   [current loss: 0.0607]\n",
            "[Epoch: 98]   [loss avg: 2.2607]   [current loss: 0.0020]\n",
            "[Epoch: 99]   [loss avg: 2.2385]   [current loss: 0.0146]\n",
            "[Epoch: 100]   [loss avg: 2.2169]   [current loss: 0.0010]\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# 使用GPU训练，可以在菜单 \"代码执行工具\" -> \"更改运行时类型\" 里进行设置\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 网络放到GPU上\n",
        "net = HybridSN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "# 开始训练\n",
        "total_loss = 0\n",
        "for epoch in range(100):\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 优化器梯度归零\n",
        "        optimizer.zero_grad()\n",
        "        # 正向传播 +　反向传播 + 优化\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print('[Epoch: %d]   [loss avg: %.4f]   [current loss: %.4f]' %(epoch + 1, total_loss/(epoch+1), loss.item()))\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JnoNpkT_GK8"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "# 模型测试\n",
        "for inputs, _ in test_loader:\n",
        "    inputs = inputs.to(device)\n",
        "    outputs = net(inputs)\n",
        "    outputs = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n",
        "    if count == 0:\n",
        "        y_pred_test =  outputs\n",
        "        count = 1\n",
        "    else:\n",
        "        y_pred_test = np.concatenate( (y_pred_test, outputs) )\n",
        "\n",
        "# 生成分类报告\n",
        "classification = classification_report(ytest, y_pred_test, digits=4)\n",
        "print(classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysGd_YDr_NA7"
      },
      "outputs": [],
      "source": [
        "from operator import truediv\n",
        "\n",
        "def AA_andEachClassAccuracy(confusion_matrix):\n",
        "    counter = confusion_matrix.shape[0]\n",
        "    list_diag = np.diag(confusion_matrix)\n",
        "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
        "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
        "    average_acc = np.mean(each_acc)\n",
        "    return each_acc, average_acc\n",
        "\n",
        "\n",
        "def reports (test_loader, y_test, name):\n",
        "    count = 0\n",
        "    # 模型测试\n",
        "    for inputs, _ in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = net(inputs)\n",
        "        outputs = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n",
        "        if count == 0:\n",
        "            y_pred =  outputs\n",
        "            count = 1\n",
        "        else:\n",
        "            y_pred = np.concatenate( (y_pred, outputs) )\n",
        "\n",
        "    if name == 'IP':\n",
        "        target_names = ['Alfalfa', 'Corn-notill', 'Corn-mintill', 'Corn'\n",
        "                        ,'Grass-pasture', 'Grass-trees', 'Grass-pasture-mowed',\n",
        "                        'Hay-windrowed', 'Oats', 'Soybean-notill', 'Soybean-mintill',\n",
        "                        'Soybean-clean', 'Wheat', 'Woods', 'Buildings-Grass-Trees-Drives',\n",
        "                        'Stone-Steel-Towers']\n",
        "    elif name == 'SA':\n",
        "        target_names = ['Brocoli_green_weeds_1','Brocoli_green_weeds_2','Fallow','Fallow_rough_plow','Fallow_smooth',\n",
        "                        'Stubble','Celery','Grapes_untrained','Soil_vinyard_develop','Corn_senesced_green_weeds',\n",
        "                        'Lettuce_romaine_4wk','Lettuce_romaine_5wk','Lettuce_romaine_6wk','Lettuce_romaine_7wk',\n",
        "                        'Vinyard_untrained','Vinyard_vertical_trellis']\n",
        "    elif name == 'PU':\n",
        "        target_names = ['Asphalt','Meadows','Gravel','Trees', 'Painted metal sheets','Bare Soil','Bitumen',\n",
        "                        'Self-Blocking Bricks','Shadows']\n",
        "\n",
        "    classification = classification_report(y_test, y_pred, target_names=target_names)\n",
        "    oa = accuracy_score(y_test, y_pred)\n",
        "    confusion = confusion_matrix(y_test, y_pred)\n",
        "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "    return classification, confusion, oa*100, each_acc*100, aa*100, kappa*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9sy64oL_NDi"
      },
      "outputs": [],
      "source": [
        "classification, confusion, oa, each_acc, aa, kappa = reports(test_loader, ytest, 'IP')\n",
        "classification = str(classification)\n",
        "confusion = str(confusion)\n",
        "file_name = \"classification_report.txt\"\n",
        "\n",
        "with open(file_name, 'w') as x_file:\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{} Kappa accuracy (%)'.format(kappa))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{} Overall accuracy (%)'.format(oa))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{} Average accuracy (%)'.format(aa))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{}'.format(classification))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{}'.format(confusion))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MLdk0wU_NF1"
      },
      "outputs": [],
      "source": [
        "# load the original image\n",
        "X = sio.loadmat('Indian_pines_corrected.mat')['indian_pines_corrected']\n",
        "y = sio.loadmat('Indian_pines_gt.mat')['indian_pines_gt']\n",
        "\n",
        "height = y.shape[0]\n",
        "width = y.shape[1]\n",
        "\n",
        "X = applyPCA(X, numComponents= pca_components)\n",
        "X = padWithZeros(X, patch_size//2)\n",
        "\n",
        "# 逐像素预测类别\n",
        "outputs = np.zeros((height,width))\n",
        "for i in range(height):\n",
        "    for j in range(width):\n",
        "        if int(y[i,j]) == 0:\n",
        "            continue\n",
        "        else :\n",
        "            image_patch = X[i:i+patch_size, j:j+patch_size, :]\n",
        "            image_patch = image_patch.reshape(1,image_patch.shape[0],image_patch.shape[1], image_patch.shape[2], 1)\n",
        "            X_test_image = torch.FloatTensor(image_patch.transpose(0, 4, 3, 1, 2)).to(device)\n",
        "            prediction = net(X_test_image)\n",
        "            prediction = np.argmax(prediction.detach().cpu().numpy(), axis=1)\n",
        "            outputs[i][j] = prediction+1\n",
        "    if i % 20 == 0:\n",
        "        print('... ... row ', i, ' handling ... ...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhnQGvCg_RQL"
      },
      "outputs": [],
      "source": [
        "predict_image = spectral.imshow(classes = outputs.astype(int),figsize =(5,5))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}